{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJqaTjuwGTBR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not for batch\n",
        "# Slide 2d product\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
        "    super(Conv2d, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.bias = bias\n",
        "\n",
        "    self.weight = Parameter(torch.rand(out_channels, in_channels, kernel_size[0], kernel_size[1]))\n",
        "    if bias:\n",
        "      self.bias = Parameter(torch.rand(out_channels, ))\n",
        "    else:\n",
        "      self.bias = torch.zeros(out_channels, )\n",
        "\n",
        "  def _conv2d(self, x):\n",
        "    input_height, input_width = x[0].shape\n",
        "    output_height = ((input_height - self.kernel_size[0]) // self.stride) + 1\n",
        "    output_width = ((input_width - self.kernel_size[1]) // self.stride) + 1\n",
        "\n",
        "    output = torch.zeros(self.out_channels, output_height, output_width)\n",
        "    for channel in range(0, self.out_channels):\n",
        "      for i in range(0, output_height):\n",
        "        for j in range(0, output_width):\n",
        "          x_i = i * self.stride\n",
        "          x_j = j * self.stride\n",
        "\n",
        "          weighted = x[:, x_i : x_i+self.kernel_size[0], x_j : x_j+self.kernel_size[1]] * self.weight[channel, :, :, :]\n",
        "          weighted_sum = weighted.sum()\n",
        "          output[channel][i][j] += weighted_sum\n",
        "    output = output + self.bias.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
        "\n",
        "    return output\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self._conv2d(F.pad(x, (self.padding, self.padding, self.padding, self.padding)))\n",
        "\n",
        "\n",
        "padding=2\n",
        "stride=2\n",
        "img = torch.rand(3, 10, 10)\n",
        "conv_layer = Conv2d(3, 5, [3, 3], stride, padding, True)\n",
        "print(conv_layer(img))\n",
        "print(F.conv2d(img, conv_layer.weight.data, bias=conv_layer.bias.data, padding=padding, stride=stride))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YcQ9z-eGppi",
        "outputId": "cc7e26b5-d916-44a4-978f-585226459927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.4531, 2.0830, 2.4913, 3.5422, 2.6706, 1.9279],\n",
            "         [2.7544, 5.9963, 6.4142, 7.8939, 8.1696, 4.7225],\n",
            "         [3.4721, 8.0339, 7.6732, 5.9775, 6.7201, 4.5327],\n",
            "         [2.7897, 7.1372, 8.5761, 7.9110, 7.2191, 4.3421],\n",
            "         [3.1882, 6.3207, 7.1098, 7.7169, 6.5752, 2.9402],\n",
            "         [2.9439, 5.7411, 4.5029, 5.3208, 5.1562, 2.9408]],\n",
            "\n",
            "        [[0.8749, 2.2232, 2.3732, 2.7181, 2.1921, 2.2062],\n",
            "         [2.0176, 6.2151, 6.9748, 6.6148, 8.0718, 5.1962],\n",
            "         [2.2631, 7.7246, 7.6625, 5.2598, 6.4408, 4.4251],\n",
            "         [1.8297, 7.4531, 7.4914, 7.2462, 6.7999, 4.6814],\n",
            "         [1.7149, 6.3982, 5.6596, 6.6082, 5.8654, 3.3896],\n",
            "         [1.8869, 5.8692, 3.4986, 4.4674, 4.8889, 2.9840]],\n",
            "\n",
            "        [[0.4590, 1.3713, 1.5271, 1.6470, 1.5569, 1.3965],\n",
            "         [1.4594, 5.3807, 6.0466, 6.2504, 6.8057, 4.2634],\n",
            "         [1.7560, 6.9333, 5.9880, 4.4307, 5.7325, 4.5617],\n",
            "         [1.6006, 6.0603, 6.5098, 6.7400, 5.2960, 4.2841],\n",
            "         [1.4064, 5.9214, 4.9917, 5.9871, 5.5419, 3.1031],\n",
            "         [1.8798, 5.0123, 3.5489, 4.1254, 4.7369, 2.4265]],\n",
            "\n",
            "        [[0.7443, 2.1727, 2.6124, 3.0989, 3.0141, 2.0623],\n",
            "         [2.9133, 7.0718, 7.7593, 7.4604, 7.8881, 5.2470],\n",
            "         [2.8649, 9.3682, 8.7764, 6.9424, 6.9597, 4.8293],\n",
            "         [2.4359, 7.8828, 9.2779, 8.7660, 7.1180, 4.1129],\n",
            "         [2.2688, 7.6960, 6.4350, 8.1270, 6.6188, 3.0883],\n",
            "         [2.7789, 5.6832, 4.1374, 5.1753, 4.5724, 2.7455]],\n",
            "\n",
            "        [[1.4642, 2.0412, 1.9110, 2.9302, 3.1123, 2.5061],\n",
            "         [1.9209, 6.3435, 6.7344, 7.7871, 8.2442, 6.1853],\n",
            "         [3.0562, 9.1595, 8.9845, 6.6549, 6.5843, 5.2024],\n",
            "         [2.4811, 8.3353, 9.5208, 9.0025, 7.6128, 5.1934],\n",
            "         [2.1964, 7.8184, 6.4330, 7.7944, 7.2352, 3.7950],\n",
            "         [2.9919, 7.3198, 4.9250, 5.6391, 6.3804, 4.1940]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[1.4531, 2.0830, 2.4913, 3.5422, 2.6706, 1.9279],\n",
            "         [2.7544, 5.9963, 6.4142, 7.8939, 8.1696, 4.7225],\n",
            "         [3.4721, 8.0339, 7.6732, 5.9775, 6.7201, 4.5327],\n",
            "         [2.7897, 7.1372, 8.5761, 7.9110, 7.2191, 4.3421],\n",
            "         [3.1882, 6.3207, 7.1098, 7.7169, 6.5752, 2.9402],\n",
            "         [2.9439, 5.7411, 4.5029, 5.3208, 5.1562, 2.9408]],\n",
            "\n",
            "        [[0.8749, 2.2232, 2.3732, 2.7181, 2.1921, 2.2062],\n",
            "         [2.0176, 6.2151, 6.9748, 6.6148, 8.0718, 5.1962],\n",
            "         [2.2631, 7.7246, 7.6625, 5.2598, 6.4408, 4.4251],\n",
            "         [1.8297, 7.4531, 7.4914, 7.2462, 6.7999, 4.6814],\n",
            "         [1.7149, 6.3982, 5.6596, 6.6082, 5.8654, 3.3896],\n",
            "         [1.8869, 5.8692, 3.4986, 4.4674, 4.8889, 2.9840]],\n",
            "\n",
            "        [[0.4590, 1.3713, 1.5271, 1.6470, 1.5569, 1.3965],\n",
            "         [1.4594, 5.3807, 6.0466, 6.2504, 6.8057, 4.2634],\n",
            "         [1.7560, 6.9333, 5.9880, 4.4307, 5.7325, 4.5617],\n",
            "         [1.6006, 6.0603, 6.5098, 6.7400, 5.2960, 4.2841],\n",
            "         [1.4064, 5.9214, 4.9917, 5.9871, 5.5419, 3.1031],\n",
            "         [1.8798, 5.0123, 3.5489, 4.1254, 4.7369, 2.4265]],\n",
            "\n",
            "        [[0.7443, 2.1727, 2.6124, 3.0989, 3.0141, 2.0623],\n",
            "         [2.9133, 7.0718, 7.7593, 7.4604, 7.8881, 5.2470],\n",
            "         [2.8650, 9.3682, 8.7764, 6.9424, 6.9597, 4.8293],\n",
            "         [2.4359, 7.8828, 9.2779, 8.7660, 7.1180, 4.1129],\n",
            "         [2.2688, 7.6960, 6.4350, 8.1270, 6.6188, 3.0883],\n",
            "         [2.7789, 5.6832, 4.1374, 5.1753, 4.5724, 2.7455]],\n",
            "\n",
            "        [[1.4642, 2.0412, 1.9110, 2.9302, 3.1123, 2.5061],\n",
            "         [1.9209, 6.3435, 6.7344, 7.7871, 8.2442, 6.1853],\n",
            "         [3.0562, 9.1595, 8.9845, 6.6549, 6.5843, 5.2024],\n",
            "         [2.4811, 8.3353, 9.5208, 9.0025, 7.6128, 5.1934],\n",
            "         [2.1964, 7.8184, 6.4330, 7.7944, 7.2352, 3.7950],\n",
            "         [2.9919, 7.3198, 4.9250, 5.6391, 6.3804, 4.1940]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not for batch\n",
        "# Flatten the kernel and windows and then do dot product\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
        "    super(Conv2d, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.bias = bias\n",
        "\n",
        "    self.weight = Parameter(torch.rand(out_channels, in_channels, kernel_size[0], kernel_size[1]))\n",
        "    if bias:\n",
        "      self.bias = Parameter(torch.rand(out_channels, ))\n",
        "    else:\n",
        "      self.bias = torch.zeros(out_channels, )\n",
        "\n",
        "  def _conv2d(self, x):\n",
        "    input_height, input_width = x[0].shape\n",
        "    output_height = ((input_height - self.kernel_size[0]) // self.stride) + 1\n",
        "    output_width = ((input_width - self.kernel_size[1]) // self.stride) + 1\n",
        "\n",
        "    output = torch.zeros(self.out_channels, output_height, output_width)\n",
        "\n",
        "    weight = self.weight.reshape(self.weight.shape[0], -1)  # flatten every kernel\n",
        "\n",
        "    for channel in range(0, self.out_channels):\n",
        "      window_stack = torch.zeros(output_height * output_width, self.in_channels * self.kernel_size[0] * self.kernel_size[1])\n",
        "      for i in range(0, output_height):\n",
        "        for j in range(0, output_width):\n",
        "          x_i = i * self.stride\n",
        "          x_j = j * self.stride\n",
        "\n",
        "          window = x[:, x_i : x_i+self.kernel_size[0], x_j : x_j+self.kernel_size[1]]\n",
        "          window = window.reshape(-1)   # flatten the window\n",
        "          window_stack[i*output_height + j] = window # add the window to the window_stack\n",
        "      weighted_sum = window_stack @ weight[channel] # dot product each window to the kernel\n",
        "      output[channel] = weighted_sum.reshape(output_height, output_width)\n",
        "\n",
        "    output = output + self.bias.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
        "    return output\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self._conv2d(F.pad(x, (self.padding, self.padding, self.padding, self.padding)))\n",
        "\n",
        "\n",
        "padding=2\n",
        "stride=2\n",
        "img = torch.rand(3, 10, 10)\n",
        "conv_layer = Conv2d(3, 5, [3, 3], stride, padding, True)\n",
        "print(conv_layer(img))\n",
        "print(F.conv2d(img, conv_layer.weight.data, bias=conv_layer.bias.data, padding=padding, stride=stride))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__n0n8HPjkkE",
        "outputId": "f113008a-acfc-4532-b130-0425548802e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.4270,  2.6039,  2.7978,  2.4597,  2.2008,  1.7372],\n",
            "         [ 2.9344,  7.6004,  7.2254,  6.9609,  5.8994,  4.3249],\n",
            "         [ 2.7976,  6.0593,  6.2952,  6.9556,  6.2254,  3.4357],\n",
            "         [ 3.3958,  6.6478,  6.2360,  6.8679,  5.5337,  2.8626],\n",
            "         [ 2.1689,  5.5544,  4.9760,  7.2194,  5.9433,  3.5074],\n",
            "         [ 2.0495,  4.2283,  5.0333,  4.6419,  4.3606,  2.8853]],\n",
            "\n",
            "        [[ 1.0778,  2.9724,  3.6974,  2.7337,  2.4701,  2.5158],\n",
            "         [ 1.7585,  5.5037,  6.7694,  5.5176,  6.0198,  3.8737],\n",
            "         [ 1.9761,  5.2306,  6.8475,  6.9044,  5.3635,  2.4086],\n",
            "         [ 1.7406,  5.4427,  4.7411,  5.0916,  4.7052,  2.5696],\n",
            "         [ 1.0850,  4.8542,  4.1027,  6.2888,  5.7497,  2.8120],\n",
            "         [ 0.8657,  2.8196,  3.1356,  2.7571,  3.0032,  1.6076]],\n",
            "\n",
            "        [[ 1.5295,  3.4482,  4.0657,  3.3698,  3.0910,  2.5728],\n",
            "         [ 2.7892,  8.8608,  8.9145,  8.9226,  7.4301,  6.1307],\n",
            "         [ 3.0756,  7.6366,  9.0439,  8.7996,  7.0920,  4.4284],\n",
            "         [ 2.8042,  7.8806,  6.7365,  7.8331,  7.1987,  4.0379],\n",
            "         [ 1.7820,  7.2502,  6.4074,  8.9056,  7.8591,  4.3082],\n",
            "         [ 1.6888,  5.3658,  5.4873,  5.5067,  4.5194,  3.5868]],\n",
            "\n",
            "        [[ 1.1426,  3.1713,  3.6450,  3.2989,  2.6454,  2.6594],\n",
            "         [ 2.6554,  8.4910, 10.0077,  7.7495,  7.9223,  5.9954],\n",
            "         [ 2.2491,  6.8766,  7.6017,  8.5604,  7.7391,  5.2185],\n",
            "         [ 2.3432,  8.2300,  7.3042,  7.1040,  6.8676,  4.8607],\n",
            "         [ 1.4437,  7.0660,  6.2360,  9.5560,  7.2889,  5.4918],\n",
            "         [ 1.4157,  4.8602,  5.4650,  5.8684,  5.7897,  3.2164]],\n",
            "\n",
            "        [[ 1.5546,  3.7817,  3.6082,  3.0201,  2.8217,  2.1198],\n",
            "         [ 1.9305,  7.8201,  8.2784,  8.1349,  6.8661,  5.4756],\n",
            "         [ 2.2351,  7.2214,  8.1324,  8.4510,  6.7519,  3.9479],\n",
            "         [ 2.0044,  7.5971,  6.4938,  6.7272,  7.1771,  4.6891],\n",
            "         [ 1.3312,  5.8430,  5.8509,  8.4506,  6.4984,  4.9463],\n",
            "         [ 1.0159,  4.4989,  5.0576,  4.8210,  4.4166,  3.8915]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[ 1.4270,  2.6039,  2.7978,  2.4597,  2.2008,  1.7372],\n",
            "         [ 2.9344,  7.6004,  7.2254,  6.9609,  5.8994,  4.3249],\n",
            "         [ 2.7976,  6.0593,  6.2952,  6.9556,  6.2254,  3.4357],\n",
            "         [ 3.3958,  6.6478,  6.2360,  6.8679,  5.5337,  2.8626],\n",
            "         [ 2.1689,  5.5544,  4.9760,  7.2194,  5.9433,  3.5074],\n",
            "         [ 2.0495,  4.2283,  5.0333,  4.6419,  4.3606,  2.8853]],\n",
            "\n",
            "        [[ 1.0778,  2.9724,  3.6974,  2.7337,  2.4701,  2.5158],\n",
            "         [ 1.7585,  5.5037,  6.7694,  5.5176,  6.0198,  3.8737],\n",
            "         [ 1.9761,  5.2306,  6.8475,  6.9044,  5.3635,  2.4086],\n",
            "         [ 1.7406,  5.4427,  4.7411,  5.0916,  4.7052,  2.5696],\n",
            "         [ 1.0850,  4.8542,  4.1027,  6.2888,  5.7497,  2.8120],\n",
            "         [ 0.8657,  2.8196,  3.1356,  2.7571,  3.0032,  1.6076]],\n",
            "\n",
            "        [[ 1.5295,  3.4482,  4.0657,  3.3698,  3.0910,  2.5728],\n",
            "         [ 2.7892,  8.8608,  8.9145,  8.9226,  7.4301,  6.1307],\n",
            "         [ 3.0756,  7.6366,  9.0439,  8.7996,  7.0920,  4.4284],\n",
            "         [ 2.8042,  7.8806,  6.7365,  7.8331,  7.1987,  4.0379],\n",
            "         [ 1.7820,  7.2502,  6.4074,  8.9056,  7.8591,  4.3082],\n",
            "         [ 1.6888,  5.3658,  5.4873,  5.5067,  4.5194,  3.5868]],\n",
            "\n",
            "        [[ 1.1426,  3.1713,  3.6450,  3.2989,  2.6454,  2.6594],\n",
            "         [ 2.6554,  8.4910, 10.0077,  7.7495,  7.9223,  5.9954],\n",
            "         [ 2.2491,  6.8766,  7.6017,  8.5604,  7.7391,  5.2185],\n",
            "         [ 2.3432,  8.2300,  7.3042,  7.1040,  6.8676,  4.8607],\n",
            "         [ 1.4437,  7.0660,  6.2360,  9.5560,  7.2889,  5.4918],\n",
            "         [ 1.4157,  4.8602,  5.4650,  5.8684,  5.7897,  3.2164]],\n",
            "\n",
            "        [[ 1.5546,  3.7817,  3.6082,  3.0201,  2.8217,  2.1198],\n",
            "         [ 1.9305,  7.8201,  8.2784,  8.1349,  6.8661,  5.4756],\n",
            "         [ 2.2351,  7.2214,  8.1324,  8.4510,  6.7519,  3.9479],\n",
            "         [ 2.0044,  7.5971,  6.4938,  6.7272,  7.1771,  4.6891],\n",
            "         [ 1.3312,  5.8430,  5.8509,  8.4506,  6.4984,  4.9463],\n",
            "         [ 1.0159,  4.4989,  5.0576,  4.8210,  4.4166,  3.8915]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not for batch\n",
        "# pad the kernel and do dot product with the whole image\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
        "    super(Conv2d, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.bias = bias\n",
        "\n",
        "    self.weight = Parameter(torch.rand(out_channels, in_channels, kernel_size[0], kernel_size[1]))\n",
        "    if bias:\n",
        "      self.bias = Parameter(torch.rand(out_channels, ))\n",
        "    else:\n",
        "      self.bias = torch.zeros(out_channels, )\n",
        "\n",
        "  def getKernelStack(self, output_height, output_width, input_height, input_width):\n",
        "    kernel_stack = torch.zeros(self.out_channels * output_height * output_width, self.in_channels * input_height * input_width)\n",
        "    for channel in range(0, self.out_channels):\n",
        "      for i in range(0, output_height):\n",
        "        for j in range(0, output_width):\n",
        "          up = i * self.stride\n",
        "          left = j * self.stride\n",
        "\n",
        "          bottom = input_height - self.kernel_size[0] - up\n",
        "          right = input_width - self.kernel_size[1] - left\n",
        "\n",
        "          kernel_stack[channel * output_height * output_width + i*output_width + j] = F.pad(self.weight[channel], (left, right, up, bottom)).reshape(-1)\n",
        "    return kernel_stack\n",
        "\n",
        "  def _conv2d(self, x):\n",
        "    input_height, input_width = x[0].shape\n",
        "    output_height = ((input_height - self.kernel_size[0]) // self.stride) + 1\n",
        "    output_width = ((input_width - self.kernel_size[1]) // self.stride) + 1\n",
        "\n",
        "    output = torch.zeros(self.out_channels, output_height, output_width)\n",
        "\n",
        "    x = x.reshape(-1)  # flatten input\n",
        "\n",
        "    kernel_stack = self.getKernelStack(output_height, output_width, input_height, input_width)\n",
        "    weighted_sum = kernel_stack @ x\n",
        "    output = weighted_sum.reshape(self.out_channels, output_height, output_width)\n",
        "\n",
        "    output = output + self.bias.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
        "    return output\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self._conv2d(F.pad(x, (self.padding, self.padding, self.padding, self.padding)))\n",
        "\n",
        "\n",
        "padding=2\n",
        "stride=2\n",
        "img = torch.rand(3, 10, 10)\n",
        "conv_layer = Conv2d(3, 5, [3, 3], stride, padding, False)\n",
        "print(conv_layer(img))\n",
        "print(F.conv2d(img, conv_layer.weight.data, bias=conv_layer.bias.data, padding=padding, stride=stride))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BFy9zAS8UBn",
        "outputId": "4716f828-24b1-4e61-a64d-c34599f3941f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.5424,  2.8086,  2.0527,  2.4725,  2.2679,  1.1477],\n",
            "         [ 2.3743,  6.8770,  6.5688,  7.9841,  6.8333,  4.8689],\n",
            "         [ 2.5246,  7.5350,  5.6906,  7.3873,  7.1638,  4.7830],\n",
            "         [ 1.8095,  7.5537,  6.7057,  6.4189,  7.3862,  5.5735],\n",
            "         [ 2.4941,  6.7883,  8.0656,  8.4806,  7.8950,  5.2561],\n",
            "         [ 1.6898,  4.7093,  5.0057,  5.0587,  5.1795,  2.5376]],\n",
            "\n",
            "        [[ 0.8665,  1.8311,  1.8487,  2.2015,  2.5681,  1.1162],\n",
            "         [ 2.8540,  6.6134,  6.9374,  7.7696,  6.3004,  3.3082],\n",
            "         [ 3.1500,  7.9742,  7.2357,  7.4050,  6.8220,  3.6889],\n",
            "         [ 3.3433,  7.3339,  5.9514,  7.0688,  8.1528,  4.4445],\n",
            "         [ 3.0505,  6.8490,  7.2185,  8.4331,  8.5285,  4.5680],\n",
            "         [ 1.4607,  4.0364,  4.7277,  5.0921,  4.1337,  2.5328]],\n",
            "\n",
            "        [[ 0.2923,  1.2190,  1.0026,  1.5044,  1.3328,  0.8121],\n",
            "         [ 2.3882,  6.3056,  5.4415,  7.0724,  5.4973,  4.3390],\n",
            "         [ 2.3874,  6.1741,  6.7679,  6.5000,  6.4788,  4.1741],\n",
            "         [ 2.4580,  6.8912,  6.0501,  6.8363,  7.0859,  4.9539],\n",
            "         [ 2.3880,  7.2736,  7.2444,  7.1593,  7.8074,  5.1259],\n",
            "         [ 2.1278,  4.5898,  5.4357,  6.1666,  5.2372,  2.5556]],\n",
            "\n",
            "        [[ 0.4068,  1.6434,  1.3245,  1.8201,  2.0688,  1.2967],\n",
            "         [ 1.7733,  6.5907,  4.8204,  7.0218,  5.3144,  4.4728],\n",
            "         [ 1.7311,  6.1185,  5.7499,  6.1655,  6.3884,  4.1072],\n",
            "         [ 1.2467,  6.3349,  6.1182,  6.6158,  6.4537,  5.4696],\n",
            "         [ 1.6701,  6.6481,  7.0261,  7.0077,  7.5146,  5.0538],\n",
            "         [ 1.3390,  4.0280,  4.9802,  5.0499,  4.9444,  2.7542]],\n",
            "\n",
            "        [[ 0.3598,  2.5009,  1.9443,  2.4307,  2.3672,  2.2617],\n",
            "         [ 2.7370,  8.1729,  7.0130,  9.0638,  8.1970,  4.7841],\n",
            "         [ 2.6167,  8.4844,  8.7774,  8.4778,  7.5039,  5.1644],\n",
            "         [ 2.4841,  8.7713,  8.1167,  7.5853,  8.9232,  6.4963],\n",
            "         [ 3.1150,  8.8060, 10.0474,  9.2062,  9.8246,  6.3450],\n",
            "         [ 2.5033,  6.1479,  6.5433,  7.9593,  6.4153,  3.3809]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[ 0.5424,  2.8086,  2.0527,  2.4725,  2.2679,  1.1477],\n",
            "         [ 2.3743,  6.8770,  6.5688,  7.9841,  6.8333,  4.8689],\n",
            "         [ 2.5246,  7.5350,  5.6906,  7.3873,  7.1638,  4.7830],\n",
            "         [ 1.8095,  7.5537,  6.7057,  6.4189,  7.3862,  5.5735],\n",
            "         [ 2.4941,  6.7883,  8.0656,  8.4806,  7.8950,  5.2561],\n",
            "         [ 1.6898,  4.7093,  5.0057,  5.0587,  5.1795,  2.5376]],\n",
            "\n",
            "        [[ 0.8665,  1.8311,  1.8487,  2.2015,  2.5681,  1.1162],\n",
            "         [ 2.8540,  6.6134,  6.9374,  7.7696,  6.3004,  3.3082],\n",
            "         [ 3.1500,  7.9742,  7.2357,  7.4050,  6.8220,  3.6889],\n",
            "         [ 3.3433,  7.3339,  5.9514,  7.0688,  8.1528,  4.4445],\n",
            "         [ 3.0505,  6.8490,  7.2185,  8.4331,  8.5285,  4.5680],\n",
            "         [ 1.4607,  4.0364,  4.7277,  5.0921,  4.1337,  2.5328]],\n",
            "\n",
            "        [[ 0.2923,  1.2190,  1.0026,  1.5044,  1.3328,  0.8121],\n",
            "         [ 2.3882,  6.3056,  5.4415,  7.0724,  5.4973,  4.3390],\n",
            "         [ 2.3874,  6.1741,  6.7679,  6.5000,  6.4788,  4.1741],\n",
            "         [ 2.4580,  6.8912,  6.0501,  6.8363,  7.0859,  4.9539],\n",
            "         [ 2.3880,  7.2736,  7.2444,  7.1593,  7.8074,  5.1259],\n",
            "         [ 2.1278,  4.5898,  5.4357,  6.1666,  5.2372,  2.5556]],\n",
            "\n",
            "        [[ 0.4068,  1.6434,  1.3245,  1.8201,  2.0688,  1.2967],\n",
            "         [ 1.7733,  6.5907,  4.8204,  7.0218,  5.3144,  4.4728],\n",
            "         [ 1.7311,  6.1185,  5.7499,  6.1655,  6.3884,  4.1072],\n",
            "         [ 1.2467,  6.3349,  6.1182,  6.6158,  6.4537,  5.4696],\n",
            "         [ 1.6701,  6.6481,  7.0261,  7.0077,  7.5146,  5.0538],\n",
            "         [ 1.3390,  4.0280,  4.9802,  5.0499,  4.9444,  2.7542]],\n",
            "\n",
            "        [[ 0.3598,  2.5009,  1.9443,  2.4307,  2.3672,  2.2617],\n",
            "         [ 2.7370,  8.1729,  7.0130,  9.0638,  8.1970,  4.7841],\n",
            "         [ 2.6167,  8.4844,  8.7774,  8.4778,  7.5039,  5.1644],\n",
            "         [ 2.4841,  8.7713,  8.1167,  7.5853,  8.9232,  6.4963],\n",
            "         [ 3.1150,  8.8060, 10.0474,  9.2062,  9.8246,  6.3450],\n",
            "         [ 2.5033,  6.1479,  6.5433,  7.9593,  6.4153,  3.3809]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not for batch\n",
        "# Just multiply the tranpose of kernelstach with the result of conv2d\n",
        "class ConvTranspose2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
        "    super(ConvTranspose2d, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.bias = bias\n",
        "\n",
        "    self.weight = Parameter(torch.rand(out_channels, in_channels, kernel_size[0], kernel_size[1]))\n",
        "    if bias:\n",
        "      self.bias = Parameter(torch.rand(in_channels, ))\n",
        "    else:\n",
        "      self.bias = torch.zeros(in_channels, )\n",
        "\n",
        "  def getKernelStack(self, output_height, output_width, input_height, input_width):\n",
        "    kernel_stack = torch.zeros(self.out_channels * output_height * output_width, self.in_channels * input_height * input_width)\n",
        "    for channel in range(0, self.out_channels):\n",
        "      for i in range(0, output_height):\n",
        "        for j in range(0, output_width):\n",
        "          up = i * self.stride\n",
        "          left = j * self.stride\n",
        "\n",
        "          bottom = input_height - self.kernel_size[0] - up\n",
        "          right = input_width - self.kernel_size[1] - left\n",
        "\n",
        "          kernel_stack[channel * output_height * output_width + i*output_width + j] = F.pad(self.weight[channel], (left, right, up, bottom)).reshape(-1)\n",
        "    return kernel_stack\n",
        "\n",
        "  def _conv_transpose2d(self, x):\n",
        "    output_height, output_width = x[0].shape\n",
        "    input_height = (output_height - 1) * self.stride + self.kernel_size[0]\n",
        "    input_width = (output_width - 1) * self.stride + self.kernel_size[1]\n",
        "\n",
        "    output = torch.zeros(self.in_channels, input_height, input_width)\n",
        "\n",
        "    x = x.reshape(-1)  # flatten input\n",
        "\n",
        "    kernel_stack = self.getKernelStack(output_height, output_width, input_height, input_width)\n",
        "    weighted_sum = kernel_stack.T @ x\n",
        "    output = weighted_sum.reshape(self.in_channels, input_height, input_width)\n",
        "\n",
        "    output = output + self.bias.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
        "    return output\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self._conv_transpose2d(F.pad(x, (self.padding, self.padding, self.padding, self.padding)))\n",
        "\n",
        "\n",
        "padding=0\n",
        "stride=1\n",
        "img = torch.rand(2, 6, 6)\n",
        "convTranspose_layer = ConvTranspose2d(3, 2, [3, 3], stride, padding, True)\n",
        "print(convTranspose_layer(img))\n",
        "print(F.conv_transpose2d(img, convTranspose_layer.weight.data, bias=convTranspose_layer.bias.data, padding=padding, stride=stride))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBZfpgSwHLxx",
        "outputId": "3493178c-2a6b-4a11-9614-9625dcffed85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9563, 1.8329, 2.4744, 2.3191, 1.9618, 2.4013, 1.6376, 0.7762],\n",
            "         [1.4549, 2.8377, 4.4750, 4.3264, 4.1578, 4.4060, 3.9030, 1.6700],\n",
            "         [1.4158, 3.5892, 4.7237, 5.3647, 6.0045, 6.1772, 4.9488, 2.4871],\n",
            "         [1.3834, 2.9721, 4.8428, 4.5803, 5.3771, 6.8222, 4.6053, 2.4863],\n",
            "         [1.5474, 3.2271, 5.0105, 5.3270, 5.6980, 6.0726, 4.7158, 2.4186],\n",
            "         [1.9194, 4.2814, 5.2582, 4.8310, 4.6661, 5.2510, 4.3296, 2.5684],\n",
            "         [1.4018, 2.8031, 4.2586, 3.2693, 3.1328, 3.0245, 3.1548, 1.8818],\n",
            "         [0.7989, 1.5837, 1.4506, 1.4636, 1.1113, 1.3969, 1.4932, 0.7837]],\n",
            "\n",
            "        [[0.9349, 1.4394, 2.1490, 2.1387, 1.9601, 2.5860, 2.0750, 1.7306],\n",
            "         [1.6959, 2.4759, 3.9531, 4.0506, 4.2698, 4.0064, 3.6522, 2.1594],\n",
            "         [2.1406, 3.9426, 4.8002, 5.3252, 6.5377, 6.4170, 5.5258, 2.7554],\n",
            "         [1.6445, 3.0900, 4.9248, 5.0682, 6.7144, 6.5434, 4.3499, 3.0820],\n",
            "         [1.8923, 2.8134, 4.7338, 5.3393, 6.2513, 6.1442, 4.8495, 3.0208],\n",
            "         [2.2771, 3.8017, 5.3384, 6.2473, 5.6358, 5.6331, 4.2920, 2.9434],\n",
            "         [2.2429, 3.1470, 4.7012, 3.8795, 3.6578, 4.1230, 3.6447, 2.3021],\n",
            "         [1.6595, 2.1490, 2.7785, 2.4635, 2.1739, 2.5660, 2.1487, 1.2718]],\n",
            "\n",
            "        [[1.1900, 1.5642, 2.4335, 2.4987, 2.9987, 2.5755, 2.6497, 1.4767],\n",
            "         [1.2427, 1.8183, 3.1351, 3.4309, 4.2189, 3.5119, 3.1908, 2.6114],\n",
            "         [1.3494, 2.6595, 4.7236, 4.8923, 6.2070, 6.9789, 4.4240, 2.8660],\n",
            "         [1.5833, 2.3050, 4.5341, 5.8968, 5.0381, 5.8221, 4.4278, 2.6857],\n",
            "         [1.5194, 2.1865, 3.7763, 5.0057, 6.0216, 6.0517, 4.1059, 3.2103],\n",
            "         [1.7535, 2.9470, 5.8749, 4.9000, 4.9484, 4.5637, 4.0413, 3.2207],\n",
            "         [1.0136, 1.6393, 3.3692, 3.5339, 3.2138, 3.3451, 2.9379, 1.9575],\n",
            "         [0.8036, 2.2683, 2.6136, 2.1176, 1.7748, 1.8077, 1.8556, 0.9926]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[0.9563, 1.8329, 2.4744, 2.3191, 1.9618, 2.4013, 1.6376, 0.7762],\n",
            "         [1.4549, 2.8377, 4.4750, 4.3264, 4.1578, 4.4060, 3.9030, 1.6700],\n",
            "         [1.4158, 3.5892, 4.7237, 5.3647, 6.0045, 6.1772, 4.9488, 2.4871],\n",
            "         [1.3834, 2.9721, 4.8428, 4.5803, 5.3771, 6.8222, 4.6053, 2.4863],\n",
            "         [1.5474, 3.2271, 5.0105, 5.3270, 5.6980, 6.0726, 4.7158, 2.4186],\n",
            "         [1.9194, 4.2814, 5.2582, 4.8310, 4.6661, 5.2510, 4.3296, 2.5684],\n",
            "         [1.4018, 2.8031, 4.2586, 3.2693, 3.1328, 3.0245, 3.1548, 1.8818],\n",
            "         [0.7989, 1.5837, 1.4506, 1.4636, 1.1113, 1.3969, 1.4932, 0.7837]],\n",
            "\n",
            "        [[0.9349, 1.4394, 2.1490, 2.1387, 1.9601, 2.5860, 2.0750, 1.7306],\n",
            "         [1.6959, 2.4759, 3.9531, 4.0506, 4.2698, 4.0064, 3.6522, 2.1594],\n",
            "         [2.1406, 3.9426, 4.8002, 5.3252, 6.5377, 6.4170, 5.5258, 2.7554],\n",
            "         [1.6445, 3.0900, 4.9248, 5.0682, 6.7144, 6.5434, 4.3499, 3.0820],\n",
            "         [1.8923, 2.8134, 4.7338, 5.3393, 6.2513, 6.1442, 4.8495, 3.0208],\n",
            "         [2.2771, 3.8017, 5.3384, 6.2473, 5.6358, 5.6331, 4.2920, 2.9434],\n",
            "         [2.2429, 3.1470, 4.7012, 3.8795, 3.6578, 4.1230, 3.6447, 2.3021],\n",
            "         [1.6595, 2.1490, 2.7785, 2.4635, 2.1739, 2.5660, 2.1487, 1.2718]],\n",
            "\n",
            "        [[1.1900, 1.5642, 2.4335, 2.4987, 2.9987, 2.5755, 2.6497, 1.4767],\n",
            "         [1.2427, 1.8183, 3.1351, 3.4309, 4.2189, 3.5119, 3.1908, 2.6114],\n",
            "         [1.3494, 2.6595, 4.7236, 4.8923, 6.2070, 6.9789, 4.4240, 2.8660],\n",
            "         [1.5833, 2.3050, 4.5341, 5.8968, 5.0381, 5.8221, 4.4278, 2.6857],\n",
            "         [1.5194, 2.1865, 3.7763, 5.0057, 6.0216, 6.0517, 4.1059, 3.2103],\n",
            "         [1.7535, 2.9470, 5.8749, 4.9000, 4.9484, 4.5637, 4.0413, 3.2207],\n",
            "         [1.0136, 1.6393, 3.3692, 3.5339, 3.2138, 3.3451, 2.9379, 1.9575],\n",
            "         [0.8036, 2.2683, 2.6136, 2.1176, 1.7748, 1.8077, 1.8556, 0.9926]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not for batch\n",
        "# add groups and dilation\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, groups=1, dilation=1, bias=True):\n",
        "    super(Conv2d, self).__init__()\n",
        "\n",
        "    assert(in_channels % groups == 0)\n",
        "    assert(out_channels % groups == 0)\n",
        "\n",
        "    self.groups = groups\n",
        "    self.dilation = dilation\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.bias = bias\n",
        "\n",
        "    self.weight = Parameter(torch.rand(out_channels, in_channels//groups, kernel_size[0], kernel_size[1]))\n",
        "    if bias:\n",
        "      self.bias = Parameter(torch.rand(out_channels, ))\n",
        "    else:\n",
        "      self.bias = torch.zeros(out_channels, )\n",
        "\n",
        "  def getKernelStack(self, output_height, output_width, input_height, input_width, dilated_kernel_size, dilated_weight):\n",
        "    kernel_stack = torch.zeros(self.out_channels//self.groups * output_height * output_width, self.in_channels//self.groups * input_height * input_width)\n",
        "    for channel in range(0, self.out_channels//self.groups):\n",
        "      for i in range(0, output_height):\n",
        "        for j in range(0, output_width):\n",
        "          up = i * self.stride\n",
        "          left = j * self.stride\n",
        "\n",
        "          bottom = input_height - dilated_kernel_size[0] - up\n",
        "          right = input_width - dilated_kernel_size[1] - left\n",
        "\n",
        "          kernel_stack[channel * output_height * output_width + i*output_width + j] = F.pad(dilated_weight[channel], (left, right, up, bottom)).reshape(-1)\n",
        "    return kernel_stack\n",
        "\n",
        "  def _conv2d(self, x):\n",
        "    group_weights = self.weight.reshape(self.groups, self.weight.shape[0]//self.groups, self.weight.shape[1], self.weight.shape[2], self.weight.shape[3])\n",
        "    dilated_kernel_size = (torch.tensor(self.kernel_size) - 1) * self.dilation + 1\n",
        "    group_dilated_weights = torch.zeros(group_weights.shape[0], group_weights.shape[1], group_weights.shape[2], dilated_kernel_size[0], dilated_kernel_size[1])\n",
        "    group_dilated_weights[:, :, :, 0::self.dilation, 0::self.dilation] = group_weights\n",
        "\n",
        "    input_height, input_width = x[0].shape\n",
        "    output_height = ((input_height - dilated_kernel_size[0]) // self.stride) + 1\n",
        "    output_width = ((input_width - dilated_kernel_size[1]) // self.stride) + 1\n",
        "    output = torch.zeros(self.out_channels, output_height, output_width)\n",
        "\n",
        "    for group in range(0, self.groups):\n",
        "      group_output = torch.zeros(self.out_channels//self.groups, output_height, output_width)\n",
        "\n",
        "      group_x = x[group*self.in_channels//self.groups : (group+1)*self.in_channels//self.groups].reshape(-1)  # flatten input\n",
        "\n",
        "      kernel_stack = self.getKernelStack(output_height, output_width, input_height, input_width, dilated_kernel_size, group_dilated_weights[group])\n",
        "      weighted_sum = kernel_stack @ group_x\n",
        "      group_output = weighted_sum.reshape(self.out_channels//self.groups, output_height, output_width)\n",
        "      output[group*self.out_channels//self.groups : (group+1)*self.out_channels//self.groups] = group_output\n",
        "    output = output + self.bias.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
        "    return output\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self._conv2d(F.pad(x, (self.padding, self.padding, self.padding, self.padding)))\n",
        "\n",
        "\n",
        "padding=2\n",
        "stride=2\n",
        "groups = 2\n",
        "dilation = 2\n",
        "img = torch.rand(6, 10, 10)\n",
        "conv_layer = Conv2d(6, 8, [3, 3], stride, padding, groups, dilation, True)\n",
        "print(conv_layer(img))\n",
        "print(F.conv2d(img, conv_layer.weight.data, bias=conv_layer.bias.data, padding=padding, stride=stride, groups=groups, dilation=dilation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrNuK5kZ0Qad",
        "outputId": "bd56438d-858b-43f7-e77e-b80511c7a69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.8316, 5.0937, 5.1571, 5.4896, 4.2682],\n",
            "         [3.7342, 7.3872, 7.7916, 9.3406, 6.4387],\n",
            "         [3.9233, 6.7700, 6.7458, 8.8428, 5.5295],\n",
            "         [4.9627, 7.0903, 7.0385, 7.9354, 5.6690],\n",
            "         [4.3209, 5.3555, 4.8767, 4.8104, 3.5950]],\n",
            "\n",
            "        [[2.5928, 4.3266, 4.7514, 5.4068, 3.3551],\n",
            "         [4.1160, 7.6977, 8.6994, 9.6977, 6.0483],\n",
            "         [4.2800, 5.8484, 7.4813, 7.4894, 5.8215],\n",
            "         [5.7874, 7.9622, 8.0109, 7.8491, 5.8200],\n",
            "         [4.2431, 5.4132, 4.9332, 4.0053, 2.6362]],\n",
            "\n",
            "        [[2.7013, 4.9302, 5.5129, 5.3269, 3.9026],\n",
            "         [4.7490, 7.3597, 9.0322, 8.8845, 5.0088],\n",
            "         [4.2753, 5.9088, 7.4032, 8.4777, 5.0179],\n",
            "         [5.7142, 7.7831, 8.8974, 8.0653, 5.3302],\n",
            "         [5.4312, 5.7792, 6.0276, 4.9845, 3.4999]],\n",
            "\n",
            "        [[1.8495, 2.9027, 3.6607, 4.5729, 3.2773],\n",
            "         [2.8428, 5.1842, 6.4025, 8.1739, 5.5141],\n",
            "         [2.3623, 4.8496, 5.9684, 6.3230, 4.9481],\n",
            "         [3.8032, 6.4507, 7.3733, 6.4317, 5.2094],\n",
            "         [3.5574, 4.3753, 3.8529, 3.1316, 2.8798]],\n",
            "\n",
            "        [[3.2816, 5.4555, 5.3866, 3.6989, 2.5896],\n",
            "         [5.2887, 7.5038, 6.9456, 7.1168, 4.8488],\n",
            "         [4.5561, 6.0459, 7.0819, 6.9015, 4.5756],\n",
            "         [4.5062, 6.9218, 6.6241, 7.4631, 5.3262],\n",
            "         [2.8120, 4.6918, 5.8833, 4.9260, 3.6704]],\n",
            "\n",
            "        [[3.2064, 4.9104, 5.4503, 4.4876, 2.9760],\n",
            "         [4.9068, 6.8634, 7.2049, 6.3582, 4.2612],\n",
            "         [5.3604, 6.7129, 7.1790, 6.7714, 5.3268],\n",
            "         [4.2820, 6.0691, 7.1682, 6.2066, 4.9564],\n",
            "         [3.3414, 3.7339, 5.1260, 4.5383, 3.1014]],\n",
            "\n",
            "        [[3.5748, 5.9765, 6.1893, 5.4453, 3.4838],\n",
            "         [5.5218, 9.0897, 8.4666, 8.5190, 6.5241],\n",
            "         [5.5872, 8.5073, 8.7985, 8.8088, 7.4246],\n",
            "         [4.8355, 8.0424, 8.3124, 9.4287, 6.7054],\n",
            "         [2.9522, 5.2070, 5.7244, 5.5146, 3.9211]],\n",
            "\n",
            "        [[3.4977, 5.3809, 5.9040, 4.9456, 2.8064],\n",
            "         [5.0587, 8.0468, 7.8786, 7.2030, 5.1735],\n",
            "         [4.7428, 6.4216, 7.9362, 8.0808, 4.9256],\n",
            "         [5.1827, 8.0035, 7.3196, 8.2008, 5.7827],\n",
            "         [2.9632, 5.2475, 6.4686, 5.3203, 4.1107]]], grad_fn=<AddBackward0>)\n",
            "tensor([[[2.8316, 5.0937, 5.1571, 5.4896, 4.2682],\n",
            "         [3.7342, 7.3872, 7.7916, 9.3406, 6.4387],\n",
            "         [3.9233, 6.7700, 6.7458, 8.8428, 5.5295],\n",
            "         [4.9627, 7.0903, 7.0385, 7.9354, 5.6690],\n",
            "         [4.3209, 5.3555, 4.8767, 4.8104, 3.5950]],\n",
            "\n",
            "        [[2.5928, 4.3266, 4.7514, 5.4068, 3.3551],\n",
            "         [4.1160, 7.6977, 8.6994, 9.6977, 6.0483],\n",
            "         [4.2800, 5.8484, 7.4813, 7.4894, 5.8215],\n",
            "         [5.7874, 7.9622, 8.0109, 7.8491, 5.8200],\n",
            "         [4.2431, 5.4132, 4.9332, 4.0053, 2.6362]],\n",
            "\n",
            "        [[2.7013, 4.9302, 5.5129, 5.3269, 3.9026],\n",
            "         [4.7490, 7.3597, 9.0322, 8.8845, 5.0088],\n",
            "         [4.2753, 5.9088, 7.4032, 8.4777, 5.0179],\n",
            "         [5.7142, 7.7831, 8.8974, 8.0653, 5.3302],\n",
            "         [5.4312, 5.7792, 6.0276, 4.9845, 3.4999]],\n",
            "\n",
            "        [[1.8495, 2.9027, 3.6607, 4.5729, 3.2773],\n",
            "         [2.8428, 5.1842, 6.4025, 8.1739, 5.5141],\n",
            "         [2.3623, 4.8496, 5.9684, 6.3230, 4.9481],\n",
            "         [3.8032, 6.4507, 7.3733, 6.4317, 5.2094],\n",
            "         [3.5574, 4.3753, 3.8529, 3.1316, 2.8798]],\n",
            "\n",
            "        [[3.2816, 5.4555, 5.3866, 3.6989, 2.5896],\n",
            "         [5.2887, 7.5038, 6.9456, 7.1168, 4.8488],\n",
            "         [4.5561, 6.0459, 7.0819, 6.9015, 4.5756],\n",
            "         [4.5062, 6.9218, 6.6241, 7.4631, 5.3262],\n",
            "         [2.8120, 4.6918, 5.8833, 4.9260, 3.6704]],\n",
            "\n",
            "        [[3.2064, 4.9104, 5.4503, 4.4876, 2.9760],\n",
            "         [4.9068, 6.8634, 7.2049, 6.3582, 4.2612],\n",
            "         [5.3604, 6.7129, 7.1790, 6.7714, 5.3268],\n",
            "         [4.2820, 6.0691, 7.1682, 6.2066, 4.9564],\n",
            "         [3.3414, 3.7339, 5.1260, 4.5383, 3.1014]],\n",
            "\n",
            "        [[3.5748, 5.9765, 6.1893, 5.4453, 3.4838],\n",
            "         [5.5218, 9.0897, 8.4666, 8.5190, 6.5241],\n",
            "         [5.5872, 8.5073, 8.7985, 8.8088, 7.4246],\n",
            "         [4.8355, 8.0424, 8.3124, 9.4287, 6.7054],\n",
            "         [2.9522, 5.2070, 5.7244, 5.5146, 3.9211]],\n",
            "\n",
            "        [[3.4977, 5.3809, 5.9040, 4.9456, 2.8064],\n",
            "         [5.0587, 8.0468, 7.8786, 7.2030, 5.1735],\n",
            "         [4.7428, 6.4216, 7.9362, 8.0808, 4.9256],\n",
            "         [5.1827, 8.0035, 7.3196, 8.2008, 5.7827],\n",
            "         [2.9632, 5.2475, 6.4686, 5.3203, 4.1107]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t3g-1HFxjGuU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}