{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56749380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import log, pi, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb599b",
   "metadata": {},
   "source": [
    "## Cross Entropy ##\n",
    "\n",
    "nn.CrossEntropyLoss()\n",
    "\n",
    "output: unnormalized logits\n",
    "\n",
    "target: softmax probability  or  indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cec89386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6459,  1.8714, -0.2603,  0.3539,  1.1255],\n",
      "        [ 0.4164,  0.3537, -0.0721, -0.9630, -2.2039]], requires_grad=True)\n",
      "tensor([[0.3057, 0.1880, 0.1005, 0.2407, 0.1651],\n",
      "        [0.0903, 0.3517, 0.0821, 0.3311, 0.1448]])\n",
      "tensor([1, 3])\n"
     ]
    }
   ],
   "source": [
    "ce_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "output = torch.randn(2, 5, requires_grad=True)\n",
    "target_prob = torch.randn(2, 5).softmax(dim=1)\n",
    "target_index = torch.tensor([1, 3], dtype=torch.long)\n",
    "print(output)\n",
    "print(target_prob)\n",
    "print(target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba0569dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7768, grad_fn=<DivBackward0>)\n",
      "tensor(1.7768, grad_fn=<DivBackward1>)\n",
      "tensor(2.2193, grad_fn=<DivBackward0>)\n",
      "tensor(2.2193, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def CrossEntropyLoss(output, target):\n",
    "    output_prob = torch.softmax(output, dim=-1)\n",
    "    if target.dim() == 2:\n",
    "        return -(torch.log(output_prob + 1e-10) * target).sum() / target.shape[0]\n",
    "    elif target.dim() == 1:\n",
    "        coorespondong_prob = output_prob[np.arange(output_prob.shape[0]), target]\n",
    "        return -torch.log(coorespondong_prob + 1e-10).sum() / target.shape[0]\n",
    "    \n",
    "print(CrossEntropyLoss(output, target_prob))\n",
    "print(ce_loss_fn(output, target_prob))\n",
    "print(CrossEntropyLoss(output, target_index))\n",
    "print(ce_loss_fn(output, target_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f12934",
   "metadata": {},
   "source": [
    "## NLL Loss ##\n",
    "\n",
    "nn.NLLLoss()\n",
    "\n",
    "output: log softmax probability\n",
    "\n",
    "target: indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9506769e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1699,  1.5913, -1.2887,  0.7471, -1.5609],\n",
      "        [-1.1157,  0.5208,  0.3123, -0.4699, -1.6789]])\n",
      "tensor([1, 3])\n"
     ]
    }
   ],
   "source": [
    "nll_loss_fn = nn.NLLLoss()\n",
    "\n",
    "output = torch.randn(2, 5)\n",
    "target_index = torch.tensor([1, 3], dtype=torch.long)\n",
    "print(output)\n",
    "print(target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3c396047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2368)\n",
      "tensor(1.2368)\n"
     ]
    }
   ],
   "source": [
    "def NLLLoss(output_prob, target):\n",
    "    coorespondong_prob = output_prob[np.arange(output_prob.shape[0]), target]\n",
    "    return - coorespondong_prob.sum() / target.shape[0]\n",
    "\n",
    "print(NLLLoss(torch.log(torch.softmax(output, -1)), target_index))\n",
    "print(nll_loss_fn(torch.log(torch.softmax(output, -1)), target_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "74b87691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2368)\n",
      "tensor(1.2368)\n"
     ]
    }
   ],
   "source": [
    "# same result\n",
    "a1 = nll_loss_fn(torch.log(torch.softmax(output, dim=-1)), target_index)\n",
    "a2 = ce_loss_fn(output, target_index)\n",
    "print(a1)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b4f2c",
   "metadata": {},
   "source": [
    "## BCE Loss ##\n",
    "\n",
    "nn.BCELoss()\n",
    "\n",
    "output: individual probability  0 < output < 1\n",
    "\n",
    "target: individual probability  0 < target < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7bd2e0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2785,  2.0216],\n",
      "        [ 0.4317, -1.3540],\n",
      "        [ 1.8208, -0.0185],\n",
      "        [ 0.0481, -0.3824]], requires_grad=True)\n",
      "tensor([[-0.2324, -0.1733],\n",
      "        [ 0.3539, -0.1443],\n",
      "        [ 1.6869, -0.3359],\n",
      "        [ 1.3514,  2.2017]])\n"
     ]
    }
   ],
   "source": [
    "bce_loss_fn = nn.BCELoss()\n",
    "\n",
    "output = torch.randn(4, 2)\n",
    "target_prob = torch.randn(4, 2)\n",
    "print(output)\n",
    "print(target_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e3dbffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7644, grad_fn=<DivBackward0>)\n",
      "tensor(0.7644, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def BCELoss(output, target):\n",
    "    return - (target * torch.log(output) + (1-target) * torch.log(1-output)).sum() / target.numel()\n",
    "\n",
    "print(BCELoss(output.sigmoid(), target_prob.sigmoid()))\n",
    "print(bce_loss_fn(output.sigmoid(), target_prob.sigmoid()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230ce5c",
   "metadata": {},
   "source": [
    "## KL Divergence Loss ##\n",
    "\n",
    "nn.KLDivLoss()\n",
    "\n",
    "output: log softmax probability\n",
    "\n",
    "target: softmax probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "06c7c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7335, -1.9119],\n",
      "        [ 0.4035, -0.9658],\n",
      "        [ 1.9480,  0.6130],\n",
      "        [-0.3847, -1.7015]])\n",
      "tensor([[ 0.1402, -0.6207],\n",
      "        [-0.1955,  0.8656],\n",
      "        [ 0.9659, -0.5352],\n",
      "        [ 1.8111,  0.8578]])\n"
     ]
    }
   ],
   "source": [
    "kl_loss_fn = nn.KLDivLoss()\n",
    "\n",
    "output = torch.randn(4, 2)\n",
    "target_prob = torch.randn(4, 2)\n",
    "print(output)\n",
    "print(target_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3256f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1562)\n",
      "tensor(0.1562)\n"
     ]
    }
   ],
   "source": [
    "def KLDivergenceLoss(output, target):\n",
    "    return -(target * (output - torch.log(target))).sum() / target.numel()\n",
    "\n",
    "print(KLDivergenceLoss(torch.log(torch.softmax(output, dim=-1)), torch.softmax(target_prob, dim=-1)))\n",
    "print(kl_loss_fn(torch.log(torch.softmax(output, dim=-1)), torch.softmax(target_prob, dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "71eafc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2437,  0.8047],\n",
      "        [-0.2910,  0.9647],\n",
      "        [ 0.0265, -0.0244],\n",
      "        [-0.0639,  0.0765]])\n",
      "tensor([1.1867, 1.2438, 0.4769, 0.6038])\n",
      "tensor([0.6257, 0.5700, 0.4748, 0.5913])\n",
      "tensor([1.1867, 1.2438, 0.4769, 0.6038])\n",
      "tensor([1.1867, 1.2438, 0.4769, 0.6038])\n"
     ]
    }
   ],
   "source": [
    "def getEntropy(target_prob):\n",
    "#     return torch.distributions.Categorical(probs = torch.softmax(target_prob, dim=-1)).entropy()\n",
    "    return -(torch.softmax(target_prob, dim=-1) * torch.log(torch.softmax(target_prob, dim=-1))).sum(dim=-1)\n",
    "\n",
    "kl_loss_fn = nn.KLDivLoss(reduction='none')\n",
    "ce_loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "kl_loss = kl_loss_fn(torch.log(torch.softmax(output, dim=-1)), torch.softmax(target_prob, dim=-1))\n",
    "ce_loss = ce_loss_fn(output, torch.softmax(target_prob, dim=-1))\n",
    "entropy = getEntropy(target_prob)\n",
    "print(kl_loss)\n",
    "print(ce_loss)\n",
    "print(entropy)\n",
    "\n",
    "# KL divergence + entropy = CrossEntropy\n",
    "print(kl_loss.sum(-1) + entropy)\n",
    "print(ce_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cac90",
   "metadata": {},
   "source": [
    "## Cosine Similarity Loss ##\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "input1: random\n",
    "\n",
    "input2: random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f1a3e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0330, -0.0483,  0.0351, -0.0431,  0.1155])\n",
      "tensor([ 0.0330, -0.0483,  0.0351, -0.0431,  0.1155])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(5, 128)\n",
    "input2 = torch.randn(5, 128)\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "def CosineSimilarity(input1, input2, eps=1e-6):\n",
    "    f1 = (input1 * input2).sum(-1)\n",
    "    f2 = ((input1**2).sum(dim=-1)**0.5 * (input2**2).sum(dim=-1)**0.5)\n",
    "    return f1 / torch.maximum(f2, torch.ones_like(f2) * eps)\n",
    "\n",
    "print(CosineSimilarity(input1, input2))\n",
    "print(cos(input1, input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "296183df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9816)\n",
      "tensor(0.9816)\n"
     ]
    }
   ],
   "source": [
    "cos_loss_fn = torch.nn.CosineEmbeddingLoss()\n",
    "print(cos_loss_fn(input1, input2, torch.ones(5)))\n",
    "print((1-cos(input1, input2)).sum() / input1.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
